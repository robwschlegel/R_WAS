[
["index.html", "WASdown Preamble", " WASdown Morgan Brand and Robert Schlegel 2017-06-29 Preamble This book was written using the bookdown R package from Yihui Xie (Xie 2017). It is a combination of work done by Hadley (@hadleywickham), Garrett (@statgarrett) and Chester (@Old_Man_Chester) with some insight from the authors. This a complementory book for a workshop held at the World Aquaculture Conference in Cape Town June 2017. We (the authors) hope to provide exposure to the world of R and some relevant online resources to students which will hopefully put them on track for being self tought coding aqucultureists. An introduction to using R, RStudio, and R Markdown by Chester Ismay is also available in a free book here and more in his DataCamp course at Effective Data Storytelling using the tidyverse. For more insight into the useage we would advice you to look through R for Data Science and ModernDive. For an example of the role within the science workflow read the Nature publication Our path to better science in less time using open data science tools and the extensive testing they have done. It is possible to adopt new workflows if there is interest from the group. The story of learning in Figure ?? was presented on the Ocean Health Index team website or in their Nature publication (Lowndes et al. (n.d.)). knitr::include_graphics(&quot;images/nature_flow.png&quot;) References "],
["colophon.html", "Colophon", " Colophon The source of the book is available here and was built with versions of R packages (and their dependent packages) given below. devtools::session_info(c(&quot;tidyverse&quot;)) ## Session info -------------------------------------------------------------- ## setting value ## version R version 3.3.0 (2016-05-03) ## system x86_64, darwin13.4.0 ## ui X11 ## language (EN) ## collate en_US.UTF-8 ## tz Africa/Johannesburg ## date 2017-06-29 ## Packages ------------------------------------------------------------------ ## package * version date source ## assertthat 0.2.0 2017-04-11 cran (@0.2.0) ## BH 1.62.0-1 2016-11-19 cran (@1.62.0-) ## bindr 0.1 2016-11-13 cran (@0.1) ## bindrcpp 0.2 2017-06-17 cran (@0.2) ## broom 0.4.2 2017-02-13 cran (@0.4.2) ## cellranger 1.1.0 2016-07-27 cran (@1.1.0) ## colorspace 1.2-6 2015-03-11 CRAN (R 3.3.0) ## curl 1.2 2016-08-13 CRAN (R 3.3.0) ## dichromat 2.0-0 2013-01-24 CRAN (R 3.3.0) ## digest 0.6.12 2017-01-27 cran (@0.6.12) ## dplyr 0.7.0 2017-06-09 cran (@0.7.0) ## forcats 0.2.0.9000 2017-06-21 Github (hadley/forcats@714063c) ## foreign 0.8-66 2015-08-19 CRAN (R 3.3.0) ## ggplot2 2.2.1.9000 2017-06-22 Github (tidyverse/ggplot2@2907cf5) ## glue 1.1.0 2017-06-13 cran (@1.1.0) ## gtable 0.2.0 2016-02-26 CRAN (R 3.3.0) ## haven 1.0.0 2016-09-23 cran (@1.0.0) ## hms 0.3 2016-11-22 cran (@0.3) ## httr 1.2.1 2016-07-03 cran (@1.2.1) ## jsonlite 1.5 2017-06-01 cran (@1.5) ## labeling 0.3 2014-08-23 CRAN (R 3.3.0) ## lattice 0.20-33 2015-07-14 CRAN (R 3.3.0) ## lazyeval 0.2.0 2016-06-12 CRAN (R 3.3.0) ## lubridate 1.6.0 2016-09-13 cran (@1.6.0) ## magrittr 1.5 2014-11-22 CRAN (R 3.3.0) ## MASS 7.3-45 2016-04-21 CRAN (R 3.3.0) ## mime 0.5 2016-07-07 CRAN (R 3.3.0) ## mnormt 1.5-5 2016-10-15 cran (@1.5-5) ## modelr 0.0.0.9000 2017-06-21 Github (hadley/modelr@5ba6af4) ## munsell 0.4.3 2016-02-13 CRAN (R 3.3.0) ## nlme 3.1-127 2016-04-16 CRAN (R 3.3.0) ## openssl 0.9.4 2016-05-25 CRAN (R 3.3.0) ## pkgconfig 2.0.1 2017-03-21 cran (@2.0.1) ## plogr 0.1-1 2016-09-24 cran (@0.1-1) ## plyr 1.8.4 2016-06-08 CRAN (R 3.3.0) ## psych 1.7.3.21 2017-03-22 cran (@1.7.3.2) ## purrr 0.2.2.2 2017-05-11 cran (@0.2.2.2) ## R6 2.2.2 2017-06-17 cran (@2.2.2) ## RColorBrewer 1.1-2 2014-12-07 CRAN (R 3.3.0) ## Rcpp 0.12.11 2017-05-22 cran (@0.12.11) ## readr 1.1.1 2017-05-16 cran (@1.1.1) ## readxl 1.0.0 2017-04-18 cran (@1.0.0) ## rematch 1.0.1 2016-04-21 cran (@1.0.1) ## reshape2 1.4.2 2016-10-22 cran (@1.4.2) ## rlang 0.1.1 2017-05-18 cran (@0.1.1) ## rvest 0.3.2 2016-06-17 CRAN (R 3.3.0) ## scales 0.4.1 2016-11-09 CRAN (R 3.3.2) ## selectr 0.3-1 2016-12-19 CRAN (R 3.3.2) ## stringi 1.1.5 2017-04-07 cran (@1.1.5) ## stringr 1.2.0 2017-02-18 cran (@1.2.0) ## tibble 1.3.3 2017-05-28 cran (@1.3.3) ## tidyr 0.6.3 2017-05-15 cran (@0.6.3) ## tidyverse 1.1.1 2017-01-27 CRAN (R 3.3.2) ## xml2 1.1.1 2017-01-24 cran (@1.1.1) Book was last updated by morganbrand on Thursday, June 29, 2017 15:39:13 SAST. "],
["intro.html", "Chapter 1 Introduction 1.1 R for Data Science 1.2 Thesisdown 1.3 Blogdown 1.4 Git and Github 1.5 Twitterverse", " Chapter 1 Introduction Before you will be in any shape to get Rrring you will need to download the basics. Luckily there are lots of resources that can guide you through this process. The following is an excerpt from the book by @statgarrett and @hadleywickham 1.1 R for Data Science Taken from R for Data Science and unchanged licensed under the Creative Commons Attribution-NonCommercial-NoDerivs 3.0 United States License. 1.1.1 R To download R, go to CRAN, the comprehensive R archive network. CRAN is composed of a set of mirror servers distributed around the world and is used to distribute R and R packages. Don’t try and pick a mirror that’s close to you: instead use the cloud mirror, https://cloud.r-project.org, which automatically figures it out for you. A new major version of R comes out once a year, and there are 2-3 minor releases each year. It’s a good idea to update regularly. Upgrading can be a bit of a hassle, especially for major versions, which require you to re-install all your packages, but putting it off only makes it worse. 1.1.2 RStudio RStudio is an integrated development environment, or IDE, for R programming. Download and install it from http://www.rstudio.com/download. RStudio is updated a couple of times a year. When a new version is available, RStudio will let you know. It’s a good idea to upgrade regularly so you can take advantage of the latest and greatest features. For this book, make sure you have RStudio 1.0.0. When you start RStudio, you’ll see two key regions in the interface: For now, all you need to know is that you type R code in the console pane, and press enter to run it. You’ll learn more as we go along! 1.1.3 The tidyverse You’ll also need to install some R packages. An R package is a collection of functions, data, and documentation that extends the capabilities of base R. Using packages is key to the successful use of R. The packages in the tidyverse share a common philosophy of data and R programming, and are designed to work together naturally. You can install the complete tidyverse with a single line of code: install.packages(&quot;tidyverse&quot;) On your own computer, type that line of code in the console, and then press enter to run it. R will download the packages from CRAN and install them on to your computer. If you have problems installing, make sure that you are connected to the internet, and that https://cloud.r-project.org/ isn’t blocked by your firewall or proxy. You will not be able to use the functions, objects, and help files in a package until you load it with library(). Once you have installed a package, you can load it with the library() function: library(tidyverse) ## Warning: package &#39;tidyverse&#39; was built under R version 3.3.2 ## Warning: package &#39;tibble&#39; was built under R version 3.3.2 ## Warning: package &#39;tidyr&#39; was built under R version 3.3.2 ## Warning: package &#39;readr&#39; was built under R version 3.3.2 ## Warning: package &#39;purrr&#39; was built under R version 3.3.2 ## Warning: package &#39;dplyr&#39; was built under R version 3.3.2 This tells you that tidyverse is loading the ggplot2, tibble, tidyr, readr, purrr, and dplyr packages. These are considered to be the core of the tidyverse because you’ll use them in almost every analysis. 1.1.4 R Markdown R Markdown provides an unified authoring framework for data science, combining your code, its results, and your prose commentary. R Markdown documents are fully reproducible and support dozens of output formats, like PDFs, Word files, slideshows, and more. R Markdown files are designed to be used in three ways: For communicating to decision makers, who want to focus on the conclusions, not the code behind the analysis. For collaborating with other data scientists (including future you!), who are interested in both your conclusions, and how you reached them (i.e. the code). As an environment in which to do data science, as a modern day lab notebook where you can capture not only what you did, but also what you were thinking. R Markdown integrates a number of R packages and external tools. This means that help is, by-and-large, not available through ?. Instead, as you work through this chapter, and use R Markdown in the future, keep these resources close to hand: R Markdown Cheat Sheet: Help &gt; Cheatsheets &gt; R Markdown Cheat Sheet, R Markdown Reference Guide: Help &gt; Cheatsheets &gt; R Markdown Reference Guide. Both cheatsheets are also available at http://rstudio.com/cheatsheets. 1.2 Thesisdown Thesisdown is built from Bookdown. It is a very useful tool to start working from if your goal is to submit your thesis using the language R Markdown. The Thesisdown package was written by @Old_Man_Chester This project was inspired by the bookdown package and is an updated version of my Senior Thesis template in the reedtemplates package here. Currently, the PDF and gitbook versions are fully-functional. The word and epub versions are developmental, have no templates behind them, and are essentially calls to the appropriate functions in bookdown. The current output for the four versions is here: PDF (Generating LaTeX file is available here with other files at in the book directory.) Word ePub gitbook Under the hood, the Reed College LaTeX template (and soon the Reed College Word template) is used to ensure that documents conform precisely to submission standards. At the same time, composition and formatting can be done using lightweight markdown syntax, and R code and its output can be seamlessly included using rmarkdown. Using thesisdown has some prerequisites which are described below. To compile PDF documents using R, you are going to need to have LaTeX installed. It can be downloaded for Windows at http://http://miktex.org/download and for Mac at http://tug.org/mactex/mactex-download.html. Follow the instructions to install the necessary packages after downloading the (somewhat large) installer files. You may need to install a few extra LaTeX packages on your first attempt to knit as well. 1.2.1 The basic filing structure 1.2.2 PDF output 1.2.3 YAML 1.3 Blogdown The beauty of a platform like Blogdown is in its ability to transport your scientific work into the public domain with very little extra effort. A website is generated from R Markdown documents. You can include all your results, analysis, graphics and can be computed and rendered dynamically from R code to your website! @xieyihui and @Amber Thomas have put together an open book using bookdown which details the process of setting up a blogdown for your own private use. A section of their book, Creating Websites with R Markdown is included below and the online version is licensed under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License. We introduce an R package, blogdown, in this short book, to teach you how to create websites using R Markdown and Hugo. If you have experience with creating websites, you may naturally ask what the benefits of using R Markdown are, and how blogdown is different with existing popular website platforms, such as WordPress. There are two major highlights of blogdown: It produces a static website, meaning the website only consists of static files such as HTML, CSS, JavaScript, and images, etc. You can host the website on any web servers (see Chapter ?? for details). The website does not require server-side scripts such as PHP or databases like WordPress does. It is just one folder of static files. We will explain more benefits of static websites in Chapter ??, when we introduce the static website generator Hugo. The website is generated from R Markdown documents (R is optional, i.e., you can use plain Markdown documents without R code chunks). This brings a huge amount of benefits, especially if your website is related to data analysis or (R) programming. Being able to use Markdown implies simplicity and more importantly, portability (e.g., you are giving yourself the chance to convert your blog posts to PDF and publish to journals or even books in the future). R Markdown gives you the benefits of dynamic documents — all your results, such as tables, graphics, and inline values, can be computed and rendered dynamically from R code, hence the results you present on your website are more likely to be reproducible. An additional yet important benefit of using R Markdown is that you will be able to write technical documents easily, due to the fact that blogdown inherits the HTML output format from bookdown (Xie 2017). For example, it is possible to write LaTeX math equations, BibTeX citations, and even theorems and proofs if you want. Please do not be misled by the word “blog” in the package name: blogdown is for general-purpose websites, and not only for blogs. For example, both authors of this book have their personal websites, where you can find information about their projects, blogs, package documentations, and so on.1 All their pages are built from blogdown and Hugo. 1.4 Git and Github The initial process of getting git sorted may be challenging but we encourage you to persist and get it set up. Again, there are several online resources which provide detailed step by steps and it is not our intention to guide you through this but rather point you towards some of the ‘good’ ones. For this section we have taken content from Happy Git and GitHub for the useR which was written by @JennyBryan and licensed under Creative Commons Attribution-NonCommercial 4.0 International License. 1.4.1 Why Git? Git is a version control system. Its original purpose was to help groups of developers work collaboratively on big software projects. Git manages the evolution of a set of files – called a repository – in a sane, highly structured way. If you have no idea what I’m talking about, think of it as the “Track Changes” features from Microsoft Word on steroids. Git has been re-purposed by the data science community. In addition to using it for source code, we use it to manage the motley collection of files that make up typical data analysis projects, which often consist of data, figures, reports, and, yes, source code. A solo data analyst, working on a single computer, will benefit from adopting version control. But not nearly enough to justify the pain of installation and workflow upheaval. There are much easier ways to get versioned back ups of your files, if that’s all you’re worried about. In my opinion, for new users, the pros of Git only outweigh the cons when you factor in the overhead of communicating and collaborating with other people. Who among us does not need to do that? Your life is much easier if this is baked into your workflow, as opposed to being a separate process that you dread or neglect. 1.4.2 Why GitHub? This is where hosting services like GitHub, Bitbucket, and GitLab come in. They provide a home for your Git-based projects on the internet. If you have no idea what I’m talking about, think of it as DropBox but much, much better. The remote host acts as a distribution channel or clearinghouse for your Git-managed project. It allows other people to see your stuff, sync up with you, and perhaps even make changes. These hosting providers improve upon traditional Unix Git servers with well-designed web-based interfaces. Even for private solo projects, it’s a good idea to push your work to a remote location for peace of mind. Why? Because it’s fairly easy to screw up your local Git repository, especially when you’re new at this. The good news is that often only the Git infrastructure is borked up. Your files are just fine! Which makes your Git pickle all the more frustrating. There are official Git solutions to these problems, but they might require expertise and patience you can’t access at 3a.m. If you’ve recently pushed your work to GitHub, it’s easy to grab a fresh copy, patch things up with the changes that only exist locally, and get on with your life. Don’t get too caught up on public versus private at this point. There are many ways to get private repositories from the major providers for low or no cost. Just get started and figure out if and how Git/GitHub is going to work for you! If you outgrow this arrangement, you can throw some combination of technical savvy and money at the problem. You can either pay for a higher level of service or self-host one of these platforms. Outside of @JennyBryan book you can find a detailed guide to getting Gited with RStudio by /(???) here. 1.5 Twitterverse You might also want to follow these guys on Twitter: Hadley Wickham @hadleywickham Garrett Grolemund @statgarrett Chester Ismay @Old_Man_Chester Yihui Xie @xieyihui Jenny Bryan @JennyBryan RStudio Tips @rstudiotips If you’re an active Twitter user, follow the #rstats hashtag. References "],
["petrol.html", "Chapter 2 Petrol 2.1 Loading and prepping the data 2.2 Distances traveled 2.3 Spending behaviour 2.4 Petrol usage per km 2.5 Petrol prices", " Chapter 2 Petrol This report shows analyses performed and figures created from 10+ years of petrol usage with a 2003 Volkswagen Polo sedan (1.4). The purpose is to illustrate the use of Rmarkdown with data analyses. 2.1 Loading and prepping the data # Load libraries library(tidyverse) library(lubridate) library(broom) ## Warning: package &#39;broom&#39; was built under R version 3.3.2 # Load data petrol &lt;- read.csv(&quot;data/petrol_info.csv&quot;) # Correct date petrol$date &lt;- as.Date(petrol$date, &quot;%d-%m-%y&quot;) # Correct &#39;full&#39; categorical label petrol$full[is.na(petrol$full)] &lt;- 0 petrol$full &lt;- factor(petrol$full, labels = c(&quot;no&quot;, &quot;yes&quot;)) petrol$full &lt;- factor(petrol$full, levels = c(&quot;yes&quot;, &quot;no&quot;)) # Remove problem rows petrol &lt;- petrol[complete.cases(petrol),] # Add month and year columns petrol$month &lt;- floor_date(petrol$date, &quot;month&quot;) petrol$year &lt;- floor_date(petrol$date, &quot;year&quot;) # Create a column showing distance between fill-ups petrol$dist &lt;- c(0,diff(as.matrix(petrol$odom))) # Total distance traveled petrol$dist_total &lt;- petrol$odom-petrol$odom[1] 2.2 Distances traveled Over the lifespan of a vehicle, one constant will always be the increasing count of the odometre. We may plot this as a time series. ggplot(data = petrol, aes(x = date, y = odom)) + geom_line() + geom_point() + scale_y_continuous(breaks = seq(80000, 200000, 20000)) + labs(y = &quot;distance (km)&quot;, x = &quot;&quot;) Figure 2.1: Line graph showing total distance traveled (km) over time. Also of interest is how far the distances between fill ups may be. There are a couple of gaps in this time series, which lend themselves to some dramatic numbers, but overall we are able to get an idea of the true distances. ggplot(data = petrol[petrol$dist &lt;= 1000,], aes(x = dist)) + geom_histogram(fill = &quot;violet&quot;, colour = &quot;grey40&quot;) Figure 2.2: Histogram showing the distances traveled between fillings. Any values over 1,000 km were subsetted out. This histogram shows a bimodal distribution with a clustering of distances around 100 kms and 600 kms. This is not so strange if you think about it as it shows that this driver would tend to either go short distances between filling up, or long distances. This is likely linked to spending behaviours, which is the next thing to investigate. 2.3 Spending behaviour We may produce another histogram to plot the amount of money spent per visit to the petrol station. ggplot(data = petrol, aes(x = cost)) + geom_histogram(aes(fill = full), colour = &quot;grey40&quot;) + labs(x = &quot;Price (R)&quot;) Figure 2.3: Histogram showing the amount of money spent per visit to the petrol station. The colours show if the tank was filled during that visit or not. This histogram is showing two different spending habits. On the left hand side we see that there are distinct columns rising out from the others. This is when the driver went to the station and spent specifically, R20, R50, R100, R200, R300 or R400. On the right hand side of the histogram we see a more normal distribution of columns. These are the prices spent when filling up the tank to full. 2.4 Petrol usage per km One of the first things any car owner wants to know about their vehicle is the mileage their vehicle is getting. And whether or not this is decreasing with wear. Because we don’t know exactly how much petrol is used between each fill up this becomes a bit tricky. We overcome this challenge somewhat by creating annual sums of petrol use. With these we may then calculate the distance traveled per litre more broadly. Monthly means are too erratic to be useful. # Create monthly means petrol_annual &lt;- petrol %&gt;% select(-full, -date, -month) %&gt;% group_by(year) %&gt;% mutate(dist2 = sum(dist)) %&gt;% mutate(litre2 = sum (litre)) %&gt;% summarise_all(mean) %&gt;% mutate(dist_litre = dist2/litre2) # Remove outliers caused during absences is.na(petrol_annual$dist_litre) &lt;- petrol_annual$dist_litre &gt; 16 # Plot it ggplot(data = petrol_annual, aes (x = year, y = dist_litre)) + geom_line() + geom_point() + geom_smooth(colour = &quot;red&quot;) + geom_smooth(method = &quot;lm&quot;) + labs(y = &quot;km/litre&quot;, x = NULL) Figure 2.4: Line graph showing the progression of the cars mileabe over time. A linear model (blue) and non-linear model (red) are fitted to these data. The grey areas around the fitted models show the standard error (se) of the fit. As we may see, the mileage appears to increase until 2013 when it then falls precipitously. The overall change in mileage for this car however appears flat when modeled linearly. 2.5 Petrol prices We’ve saved the best for last as the most interesting thing for most people that could be extracted from these records is the price of petrol over the last decade. Both how much petrol costs per litre and how much must be spent every time we pull up to the station. First we see a lolliplot of how much was spent at each station visit. # Calculate total amount spent petrol$cost_total &lt;- cumsum(petrol$cost) # Lolli plot ggplot(data = petrol, aes(x = date, y = cost)) + geom_point(aes(colour = full)) + geom_segment(aes(xend = date, y = 0, yend = cost, colour = full)) + labs(y = &quot;cost (R)&quot;, x = &quot;&quot;) Figure 2.5: Lolliplot showing . And then the price per litre averaged per month. # Price/ litre/ month petrol_monthly &lt;- petrol %&gt;% select(-full, -date, -year) %&gt;% group_by(month) %&gt;% summarise_all(mean) %&gt;% mutate(price_litre = cost/litre) # Fill in missing months month_index &lt;- data.frame(month = seq(petrol_monthly$month[1], petrol_monthly$month[nrow(petrol_monthly)], by = &quot;month&quot;)) petrol_monthly &lt;- merge(petrol_monthly, month_index, by = &quot;month&quot;, all.y = TRUE) petrol_trend &lt;- lm(petrol_monthly$price_litre ~ seq(1:nrow(petrol_monthly))) petrol_augment &lt;- augment(petrol_trend) petrol_tidy &lt;- tidy(petrol_trend) petrol_glance &lt;- glance(petrol_trend) # petrol_tidy$estimate[2]*12 # R 0.72/ month # Line graph ggplot(data = petrol_monthly, aes(x = month, y = price_litre)) + geom_line() + geom_point() + geom_smooth(method = &quot;lm&quot;) + geom_text(aes(x = as.Date(&quot;2009-01-01&quot;), y = 13, label = paste0(&quot;Increase = R&quot;, round(petrol_tidy$estimate[2]*12, 2), &quot;/year&quot;))) + # geom_point(data = petrol[187,], colour = &quot;red&quot;) # scale_y_continuous(breaks = seq(80000, 200000, 20000)) + labs(y = &quot;R/litre&quot;, x = &quot;&quot;) And there we have it. Petrol prices in SA have increased R0.72/year over the last 10 years. "],
["bananas.html", "Chapter 3 Bananas 3.1 Loading the data 3.2 Investigating by bunch 3.3 Investigating by field 3.4 Production per hectare", " Chapter 3 Bananas On my farm we have a total of 40 hectares of land. Of this 18 hectares is natural forest with 16 hectares of sugar cane and 6 hectares of bananas. Bananas grow throughout the year and from sucker to fruit is approximately 18 months. Under field management practices we are able to maintain three stages of banana trees on each spot thereby decreasing the time to fruit to six month intervals. It is recommended that every 10 years the field is to be replanted to maximize production however, these banana fields have not been replanted recently and it is our intention to investigate what this may mean for the production. 3.1 Loading the data I transcribe my raw data into Microsoft Excel from the books. For me this is the easiest way to meticulously enter data and when the data sets are not to large finding errors can be done by changing the sort and filter functions within MS Excel. Once I am ready to import data into RStudio the file is saved as a .csv file using the MS Excel drop down option in the save menu. Data are easiest to work with when it is in long format, i.e.. each row represents a single observation. This is not crucial because it can be transformed using R. # Load the relevant packages for loading and manipulaiton library(tidyverse) # Read in the data using `readr` from the `tidyverse` package production &lt;- read_csv(&quot;data/Banana Production.csv&quot;) # A quick look to make sure the data looks like we expect head(production) ## # A tibble: 6 x 4 ## Date Field Bunches weight ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 12/3/07 102 162 990 ## 2 12/10/07 101 134 1800 ## 3 12/18/07 93 115 1494 ## 4 12/18/07 96 12 198 ## 5 12/18/07 1011 145 1620 ## 6 12/18/07 102 37 288 Once the data are loaded and looks like the right stuff I get on to making sure my columns are set as either date, factor, or number. There are multiple ways to do this but I like to use lubridate (Grolemund, Spinu, and Wickham 2016) when working with dates and the Tidyverse group namely dplyr (Wickham et al. 2017) for creating factors. 3.1.1 Setting date # Load lubridate to play with the data values library(lubridate) # Making the date coloumn actual date values production$Date &lt;- as.Date(production$Date, &quot;%m/%d/%y&quot;) # I might want to have the month and year as unique values so I have created floor dates for each # Add month and year columns production$month &lt;- floor_date(production$Date, &quot;month&quot;) production$year &lt;- floor_date(production$Date, &quot;year&quot;) 3.2 Investigating by bunch It is sometimes useful to use a standard dat or data to assign to the data you wish to work with. # Open the dat data frame from the environment panel dat &lt;- production %&gt;% mutate(Field = as.factor(Field)) 3.2.1 Bunches per month If we were to try and plot the data for number of bunches harvested per month we can start to see that there is some kind of cyclic trend (Figure 3.1). On the plot I added a smooth (a model) in blue but there seems to be a problem with what it is doing. To have a look at what this problem might be I will inspect the data frame and trouble shoot names(dat) ## [1] &quot;Date&quot; &quot;Field&quot; &quot;Bunches&quot; &quot;weight&quot; &quot;month&quot; &quot;year&quot; ggplot(data = dat, aes(x = month, y = Bunches)) + geom_bar(stat = &quot;identity&quot;) + geom_smooth(method = &quot;loess&quot;, span = 0.2) + scale_x_date(date_breaks = &quot;3 month&quot;, date_labels = &quot;%b %y&quot;) + theme(axis.text.x = element_text(angle=90, vjust = 0.5)) + labs(y = &quot;Banana bunches&quot;, x = &quot;Time&quot;) Figure 3.1: Bar graph showing the number of banana bunches harvested per month. 3.2.1.1 Problematic smooth # The str function allows you to see both the variable type and the values. str(dat) ## Classes &#39;tbl_df&#39;, &#39;tbl&#39; and &#39;data.frame&#39;: 836 obs. of 6 variables: ## $ Date : Date, format: &quot;2007-12-03&quot; &quot;2007-12-10&quot; ... ## $ Field : Factor w/ 5 levels &quot;93&quot;,&quot;96&quot;,&quot;101&quot;,..: 4 3 1 2 5 4 1 2 5 3 ... ## $ Bunches: int 162 134 115 12 145 37 95 13 96 71 ... ## $ weight : int 990 1800 1494 198 1620 288 882 378 1008 558 ... ## $ month : Date, format: &quot;2007-12-01&quot; &quot;2007-12-01&quot; ... ## $ year : Date, format: &quot;2007-01-01&quot; &quot;2007-01-01&quot; ... After looking at both the str and the data frame the problem is that Bunches are not being summed by month. This is an easy fix. If we want to create a summary data set to only include the sum total of banana bunches per month we can simply use dplyr and the pipe function. This creates a sum total for bunches.month-1 and the blue line now fits the plot more appropriately (Figure 3.2) names(dat) ## [1] &quot;Date&quot; &quot;Field&quot; &quot;Bunches&quot; &quot;weight&quot; &quot;month&quot; &quot;year&quot; # Using dply to group the data by month and year, create a new column for the sum of bunches picked per month, then ungroup dat.sum_m &lt;- dat %&gt;% group_by(month, year) %&gt;% summarise(bunches.m = sum(Bunches)) %&gt;% ungroup() # Plotting the data ggplot(data = dat.sum_m, aes(x = month, y = bunches.m)) + geom_bar(stat = &quot;identity&quot;) + geom_smooth(method = &quot;loess&quot;, span = 0.2) + scale_x_date(date_breaks = &quot;3 month&quot;, date_labels = &quot;%b %y&quot;) + theme(axis.text.x = element_text(angle=90, vjust = 0.5)) + labs(y = &quot;Banana bunches&quot;, x = &quot;Time&quot;) Figure 3.2: Bar graph showing the sum of banana bunches harvested per month with a smooth fitted in blue. From the trend observed in Figure 3.2 it seems apparent that there may be differences in the monthly output which we could look at. # I am going to modify an existing dataframe so I will assign it to &#39;a&#39; as to not back track a &lt;- dat.sum_m # The month and year are going to be pulled out of the date and given their own coloumn a$y&lt;-year(a$year) a$m&lt;-month(a$month) # If I want to use the month as anything other than a date I should tell R it is a factor a1 &lt;- a %&gt;% mutate(m = as.factor(m)) Now that the data are ready to be looked at as bunches per month a simple box plot can tell a quick visual story # a quick boxplot for the bunches harvested per month ggplot(data = a1, aes(x = m, y = bunches.m)) + geom_boxplot() + geom_jitter() + labs(y = &quot;Banana bunches&quot;, x = &quot;Month&quot;) Figure 3.3: Boxplot showing the total banana bunches harvested per month. 3.2.2 Statistics Are the number of bunches harvest per month statistically different? To answer this we will run a quick one-way ANOVA library(broom) aov &lt;- aov(bunches.m ~ m, data = a1) # The tidyed tidy(aov) ## term df sumsq meansq statistic p.value ## 1 m 11 3159730 287248.20 8.132671 8.659346e-10 ## 2 Residuals 93 3284786 35320.28 NA NA tidy(TukeyHSD(aov)) ## term comparison estimate conf.low conf.high adj.p.value ## 1 m 2-1 125.222222 -171.81647 422.260918 9.579975e-01 ## 2 m 3-1 220.000000 -77.03870 517.038696 3.634513e-01 ## 3 m 4-1 12.888889 -284.14981 309.927585 1.000000e+00 ## 4 m 5-1 -7.444444 -304.48314 289.594252 1.000000e+00 ## 5 m 6-1 -166.555556 -463.59425 130.483141 7.682453e-01 ## 6 m 7-1 -322.444444 -619.48314 -25.405748 2.153135e-02 ## 7 m 8-1 -271.333333 -568.37203 25.705363 1.075045e-01 ## 8 m 9-1 -244.152778 -550.33326 62.027702 2.560930e-01 ## 9 m 10-1 -112.527778 -418.70826 193.652702 9.848828e-01 ## 10 m 11-1 -162.777778 -468.95826 143.402702 8.231617e-01 ## 11 m 12-1 -348.000000 -645.03870 -50.961304 8.554275e-03 ## 12 m 3-2 94.777778 -202.26092 391.816474 9.952604e-01 ## 13 m 4-2 -112.333333 -409.37203 184.705363 9.811249e-01 ## 14 m 5-2 -132.666667 -429.70536 164.372029 9.376806e-01 ## 15 m 6-2 -291.777778 -588.81647 5.260918 5.892033e-02 ## 16 m 7-2 -447.666667 -744.70536 -150.627971 1.325711e-04 ## 17 m 8-2 -396.555556 -693.59425 -99.516859 1.240745e-03 ## 18 m 9-2 -369.375000 -675.55548 -63.194520 5.773603e-03 ## 19 m 10-2 -237.750000 -543.93048 68.430480 2.931045e-01 ## 20 m 11-2 -288.000000 -594.18048 18.180480 8.540437e-02 ## 21 m 12-2 -473.222222 -770.26092 -176.183526 4.065441e-05 ## 22 m 4-3 -207.111111 -504.14981 89.927585 4.582263e-01 ## 23 m 5-3 -227.444444 -524.48314 69.594252 3.134050e-01 ## 24 m 6-3 -386.555556 -683.59425 -89.516859 1.878265e-03 ## 25 m 7-3 -542.444444 -839.48314 -245.405748 1.398298e-06 ## 26 m 8-3 -491.333333 -788.37203 -194.294637 1.720851e-05 ## 27 m 9-3 -464.152778 -770.33326 -157.972298 1.176102e-04 ## 28 m 10-3 -332.527778 -638.70826 -26.347298 2.141590e-02 ## 29 m 11-3 -382.777778 -688.95826 -76.597298 3.471610e-03 ## 30 m 12-3 -568.000000 -865.03870 -270.961304 3.833872e-07 ## 31 m 5-4 -20.333333 -317.37203 276.705363 1.000000e+00 ## 32 m 6-4 -179.444444 -476.48314 117.594252 6.751512e-01 ## 33 m 7-4 -335.333333 -632.37203 -38.294637 1.363754e-02 ## 34 m 8-4 -284.222222 -581.26092 12.816474 7.409549e-02 ## 35 m 9-4 -257.041667 -563.22215 49.138813 1.911989e-01 ## 36 m 10-4 -125.416667 -431.59715 180.763813 9.657731e-01 ## 37 m 11-4 -175.666667 -481.84715 130.513813 7.415294e-01 ## 38 m 12-4 -360.888889 -657.92759 -63.850193 5.233516e-03 ## 39 m 6-5 -159.111111 -456.14981 137.927585 8.160043e-01 ## 40 m 7-5 -315.000000 -612.03870 -17.961304 2.778753e-02 ## 41 m 8-5 -263.888889 -560.92759 33.149807 1.317895e-01 ## 42 m 9-5 -236.708333 -542.88881 69.472146 2.994160e-01 ## 43 m 10-5 -105.083333 -411.26381 201.097146 9.912727e-01 ## 44 m 11-5 -155.333333 -461.51381 150.847146 8.632505e-01 ## 45 m 12-5 -340.555556 -637.59425 -43.516859 1.127501e-02 ## 46 m 7-6 -155.888889 -452.92759 141.149807 8.349898e-01 ## 47 m 8-6 -104.777778 -401.81647 192.260918 9.890943e-01 ## 48 m 9-6 -77.597222 -383.77770 228.583258 9.994023e-01 ## 49 m 10-6 54.027778 -252.15270 360.208258 9.999830e-01 ## 50 m 11-6 3.777778 -302.40270 309.958258 1.000000e+00 ## 51 m 12-6 -181.444444 -478.48314 115.594252 6.598402e-01 ## 52 m 8-7 51.111111 -245.92759 348.149807 9.999868e-01 ## 53 m 9-7 78.291667 -227.88881 384.472146 9.993502e-01 ## 54 m 10-7 209.916667 -96.26381 516.097146 4.849922e-01 ## 55 m 11-7 159.666667 -146.51381 465.847146 8.406007e-01 ## 56 m 12-7 -25.555556 -322.59425 271.483141 1.000000e+00 ## 57 m 9-8 27.180556 -278.99992 333.361035 1.000000e+00 ## 58 m 10-8 158.805556 -147.37492 464.986035 8.452559e-01 ## 59 m 11-8 108.555556 -197.62492 414.736035 9.886365e-01 ## 60 m 12-8 -76.666667 -373.70536 220.372029 9.992910e-01 ## 61 m 10-9 131.625000 -183.43211 446.682115 9.605881e-01 ## 62 m 11-9 81.375000 -233.68211 396.432115 9.992863e-01 ## 63 m 12-9 -103.847222 -410.02770 202.333258 9.920825e-01 ## 64 m 11-10 -50.250000 -365.30711 264.807115 9.999940e-01 ## 65 m 12-10 -235.472222 -541.65270 70.708258 3.070082e-01 ## 66 m 12-11 -185.222222 -491.40270 120.958258 6.732661e-01 3.3 Investigating by field Across the farm there are three ‘fields’ based on their location. When the bunches are harvested the data for field of origin is also captured. It is interesting to know how each field is performing. # Creating a cum for each month grouped by field names(dat) ## [1] &quot;Date&quot; &quot;Field&quot; &quot;Bunches&quot; &quot;weight&quot; &quot;month&quot; &quot;year&quot; dat.sum_m.f &lt;- dat %&gt;% group_by(month, year, Field) %&gt;% summarise(bunches.m.f = sum(Bunches)) As described earlier there are different fields which are picked from. A look at the production of bunches by field in Figure 3.4 highlights the fact the two fields (f102 and f93) were taken out of production. ggplot(data = dat.sum_m.f, aes(x = month, y = bunches.m.f)) + geom_bar(stat = &quot;identity&quot;) + geom_smooth(method = &quot;loess&quot;, span = 0.2) + scale_x_date(date_breaks = &quot;12 month&quot;, date_labels = &quot;%y&quot;) + theme(axis.text.x = element_text(angle=90, vjust = 0.5)) + labs(y = &quot;Banana bunches&quot;, x = &quot;Year&quot;) + facet_wrap(~Field, ncol = 2) Figure 3.4: Bar graph showing the sum of banana bunches harvested per month per field with a smooth fitted in blue. 3.3.1 Cumulative bunches per field It seems interesting to look at a field as a continuous unit and measure the cumulative harvest over time. # Creating a cumulative bunches harvest for each field names(dat) ## [1] &quot;Date&quot; &quot;Field&quot; &quot;Bunches&quot; &quot;weight&quot; &quot;month&quot; &quot;year&quot; dat.sum_f &lt;- dat %&gt;% group_by(Field) %&gt;% mutate(cumsum = cumsum(Bunches)) %&gt;% ungroup() str(dat.sum_f) ## Classes &#39;tbl_df&#39;, &#39;tbl&#39; and &#39;data.frame&#39;: 836 obs. of 7 variables: ## $ Date : Date, format: &quot;2007-12-03&quot; &quot;2007-12-10&quot; ... ## $ Field : Factor w/ 5 levels &quot;93&quot;,&quot;96&quot;,&quot;101&quot;,..: 4 3 1 2 5 4 1 2 5 3 ... ## $ Bunches: int 162 134 115 12 145 37 95 13 96 71 ... ## $ weight : int 990 1800 1494 198 1620 288 882 378 1008 558 ... ## $ month : Date, format: &quot;2007-12-01&quot; &quot;2007-12-01&quot; ... ## $ year : Date, format: &quot;2007-01-01&quot; &quot;2007-01-01&quot; ... ## $ cumsum : int 162 134 115 12 145 199 210 25 241 205 ... In Figure 3.5 the cumulative number of bunches harvested for each field highlights that they are not all performing the same. We could quickly add a linear model to this to further visualize the trend. ggplot(data = dat.sum_f, aes(x = Date, y = cumsum, colour = Field)) + geom_line() + #geom_bar(stat = &quot;identity&quot;) + #geom_smooth(method = &quot;lm&quot;) + #scale_x_date(date_breaks = &quot;12 month&quot;, date_labels = &quot;%y&quot;) + #theme(axis.text.x = element_text(angle=90, vjust = 0.5)) + labs(y = &quot;Banana bunches&quot;, x = &quot;Year&quot;) Figure 3.5: Line graph showing the cumulative harvest for banana bunches per field. #facet_wrap(~Field, ncol = 2) 3.3.2 Cumulative weight per field It seems interesting to look at a field as a continuous unit and measure the cumulative harvest over time. # Creating a cumulative bunches harvest for each field names(dat) ## [1] &quot;Date&quot; &quot;Field&quot; &quot;Bunches&quot; &quot;weight&quot; &quot;month&quot; &quot;year&quot; dat.sum_f.w &lt;- dat %&gt;% group_by(Field) %&gt;% mutate(cumsum = cumsum(weight)) names(dat.sum_f.w) ## [1] &quot;Date&quot; &quot;Field&quot; &quot;Bunches&quot; &quot;weight&quot; &quot;month&quot; &quot;year&quot; &quot;cumsum&quot; ggplot(data = dat.sum_f.w, aes(x = Date, y = cumsum, colour = Field)) + geom_line() + #geom_bar(stat = &quot;identity&quot;) + #geom_smooth(method = &quot;lm&quot;) + #scale_x_date(date_breaks = &quot;12 month&quot;, date_labels = &quot;%y&quot;) + #theme(axis.text.x = element_text(angle=90, vjust = 0.5)) + labs(y = &quot;Weight (kg)&quot;, x = &quot;Year&quot;) + scale_y_continuous(breaks = seq(0, 400000, 50000)) + theme_bw() #facet_wrap(~Field, ncol = 2) The awesome thing about this is that you can very easily turn a plot into something more than just a plot using plotly #devtools::install_github(&quot;ropensci/plotly&quot;) #devtools::install_github(&quot;hadley/ggplot2&quot;) library(plotly) bunch &lt;- ggplot(data = dat.sum_f, aes(x = Date, y = cumsum, colour = Field)) + geom_line() + #geom_bar(stat = &quot;identity&quot;) + #geom_smooth(method = &quot;lm&quot;) + scale_y_continuous(breaks = seq(0, 20000, 5000)) + theme_bw() + theme(legend.direction = &quot;horizontal&quot;, legend.justification = &quot;center&quot;, legend.position = &quot;top&quot;) + #scale_x_date(date_breaks = &quot;12 month&quot;, date_labels = &quot;%y&quot;) + #theme(axis.text.x = element_text(angle=90, vjust = 0.5)) + labs(y = &quot;Number of bunches&quot;, x = &quot;Year&quot;) #facet_wrap(~Field, ncol = 2) weight &lt;- ggplot(data = dat.sum_f.w, aes(x = Date, y = cumsum, colour = Field)) + geom_line() + #geom_bar(stat = &quot;identity&quot;) + #geom_smooth(method = &quot;lm&quot;) + #geom_smooth(method = &quot;loess&quot;, span = 0.1) + #scale_x_date(date_breaks = &quot;12 month&quot;, date_labels = &quot;%y&quot;) + #theme(axis.text.x = element_text(angle=90, vjust = 0.5)) + labs(y = &quot;Cumulative weight (kg)&quot;, x = &quot;Year&quot;) + scale_y_continuous(breaks = seq(0, 400000, 50000)) + theme_bw() + theme(legend.direction = &quot;horizontal&quot;, legend.justification = &quot;center&quot;, legend.position = &quot;top&quot;) #facet_wrap(~field, ncol = 2) library(gridExtra) grid.arrange(bunch, weight, nrow = 1) 3.4 Production per hectare The fields are not all the same size which we can standardise to a data &lt;- dat %&gt;% group_by(Field) %&gt;% mutate(cumsum = cumsum(weight)) %&gt;% ungroup() %&gt;% mutate(Field = stringr::str_replace(Field, &quot;93&quot;, &quot;f93&quot;), Field = stringr::str_replace(Field, &quot;96&quot;, &quot;f96&quot;), Field = stringr::str_replace(Field, &quot;101&quot;, &quot;f101&quot;), Field = stringr::str_replace(Field, &quot;1011&quot;, &quot;f1011&quot;), Field = stringr::str_replace(Field, &quot;102&quot;, &quot;f102&quot;)) %&gt;% spread(key = Field, value = cumsum) %&gt;% group_by(month) %&gt;% mutate(ha.93 = f93 /1.51, ha.96 = f96 /1.31, ha.101 = f101/2.07, ha.1011 = ff1011/2.21, ha.102 = f102/1.12) dat.v2 &lt;- data %&gt;% select(month, ha.93, ha.96, ha.101, ha.1011, ha.102) %&gt;% gather(Field, Weight, 2:6)%&gt;% drop_na() I want to put the plot for per hectare side by side to the weight per field. I may need to adjust the level of factors. PROBLEM - I DONT KNOW HOW!!! names(dat.v2) ## [1] &quot;month&quot; &quot;Field&quot; &quot;Weight&quot; ggplot(data = dat.v2, aes(x = month, y = Weight, colour = Field)) + geom_line() + #geom_bar(stat = &quot;identity&quot;) + #geom_smooth(method = &quot;lm&quot;) + #scale_x_date(date_breaks = &quot;12 month&quot;, date_labels = &quot;%y&quot;) + #theme(axis.text.x = element_text(angle=90, vjust = 0.5)) + labs(y = &quot;Weight (kg)&quot;, x = &quot;Year&quot;) + #scale_y_continuous(breaks = seq(0, 400000, 50000)) + theme_bw() #facet_wrap(~Field, ncol = 2) #devtools::install_github(&quot;ropensci/plotly&quot;) #devtools::install_github(&quot;hadley/ggplot2&quot;) library(plotly) area &lt;- ggplot(data = dat.v2, aes(x = month, y = Weight, colour = Field)) + geom_line() + #geom_bar(stat = &quot;identity&quot;) + #geom_smooth(method = &quot;lm&quot;) + #scale_x_date(date_breaks = &quot;12 month&quot;, date_labels = &quot;%y&quot;) + #theme(axis.text.x = element_text(angle=90, vjust = 0.5)) + labs(y = &quot;Production per hectare&quot;, x = &quot;Year&quot;) + scale_y_continuous(limits=c(0,180000), breaks = seq(0, 180000, 20000)) + ggtitle(&quot;A&quot;) + theme_bw() + ggtitle(&quot;A&quot;) + theme(legend.direction = &quot;horizontal&quot;, legend.justification = &quot;center&quot;, legend.position = &quot;top&quot;) #facet_wrap(~Field, ncol = 2) weight &lt;- ggplot(data = dat.sum_f.w, aes(x = Date, y = cumsum, colour = Field)) + geom_line() + #geom_bar(stat = &quot;identity&quot;) + #geom_smooth(method = &quot;lm&quot;) + #geom_smooth(method = &quot;loess&quot;, span = 0.1) + #scale_x_date(date_breaks = &quot;12 month&quot;, date_labels = &quot;%y&quot;) + #theme(axis.text.x = element_text(angle=90, vjust = 0.5)) + labs(y = &quot;Cumulative weight (kg)&quot;, x = &quot;Year&quot;) + scale_y_continuous(limits=c(0,300000), breaks = seq(0, 300000, 50000)) + theme_bw() + ggtitle(&quot;B&quot;) + theme(legend.direction = &quot;horizontal&quot;, legend.justification = &quot;center&quot;, legend.position = &quot;top&quot;) #facet_wrap(~field, ncol = 2) library(gridExtra) grid.arrange(area, weight, nrow = 1) References "],
["final-words.html", "Chapter 4 Final Words", " Chapter 4 Final Words To summarize, R, Rstudio, GitHub, and many other R related tie-ins are capable of adding an unbleiveable amount of substance to our work. Furthermore, object oriented command line programming (such as R) is no longer the realm exclusively of hard core nerds. One no longer needs to speak Klingon to be a coder. We have shown in this book that there are now a massive amount of resources freely available via the internet that one may use to jump into the world of R with both feet. It is the hope of the authors that we have done enough to spark the reader’s interest and that after this workshop serious consideration will be given to changing workflows over from whatever pointy clicky software was being used to the more scientifically appropriate method of using code. Whereas the short-term effort may feel painful, we can guarantee that the long-term benefits more than make up for any initial discomfort. "],
["references.html", "References", " References "]
]
